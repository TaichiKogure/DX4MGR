æ–¹å‘æ€§ã¨ã—ã¦ã¯ **ã€Œrun_v7.py ãŒå‘¼ã¶ãƒ¡ã‚¤ãƒ³ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ã€runner/adapters.py ã®æ¨™æº–ãƒ•ãƒ­ãƒ¼ï¼ˆSMALL_EXPâ†’PROTOâ†’BUNDLEâ†’DRï¼‰ã¸å·®ã—æ›¿ãˆã€**ã—ã€ãã®ä¸Šã§ **ã‚²ãƒ¼ãƒˆåˆ¥ã®è©°ã¾ã‚Šï¼ˆå¾…ã¡ãƒ»WIPï¼‰ã‚’â€œå¼·åˆ¶çš„ã«è¦‹ãˆã‚‹åŒ–â€**ã™ã‚‹ã®ãŒæœ€çŸ­ã§ã™ã€‚

ä»¥ä¸‹ã®æ–¹é‡ã§æ‰‹ã‚’å…¥ã‚Œã‚‹ã®ãŒå …ã„ã§ã™ã€‚

- **ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æœ¬ä½“**ï¼š`simulator_v7.py` ã« *æ¨™æº–ãƒ•ãƒ­ãƒ¼ç‰ˆ* `simulate_standard_flow_v7()` ã‚’è¿½åŠ ï¼ˆrunner/adapters ã‚’åˆ©ç”¨ï¼‰
- **WIPã‚’æœ¬æ°—ã§å‡ºã™**ï¼š`core/engine.py` ã§ WIP ã‚’ä¸€å®šé–“éš”ã§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆãƒãƒ¼ãƒ‰åˆ¥WIPï¼‰
- **ãƒ¡ãƒˆãƒªã‚¯ã‚¹å¼·åŒ–**ï¼š`analysis/metrics.py` ã« WIPé›†è¨ˆï¼ˆãƒãƒ¼ãƒ‰åˆ¥å¹³å‡WIPï¼‰ã‚’è¿½åŠ 
- **å¯è¦–åŒ–å¼·åŒ–**ï¼š`visualizer_v7.py` ã«
  - ã‚·ãƒŠãƒªã‚ªÃ—ã‚²ãƒ¼ãƒˆã®å¹³å‡å¾…ã¡æ™‚é–“ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
  - ã‚·ãƒŠãƒªã‚ªÃ—ã‚²ãƒ¼ãƒˆã®å¹³å‡WIPãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
- **ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ¥ç¶š**ï¼š`run_v7.py` ã® Step2ï¼ˆãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­ï¼‰ã‚’æ¨™æº–ãƒ•ãƒ­ãƒ¼ç‰ˆã«åˆ‡æ›¿

---

## å¤‰æ›´æ¡ˆï¼ˆã‚³ãƒ¼ãƒ‰ï¼‰

### 1) WIPã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’ã‚¨ãƒ³ã‚¸ãƒ³ã«å®Ÿè£…ï¼ˆãƒãƒ¼ãƒ‰åˆ¥WIPï¼‰
```python
import heapq
from typing import List, Dict, Any, Callable
from core.entities import Job
from core.gates import GateNode

class SimulationEngine:
    def __init__(self, rng=None, sampling_interval: float = 1.0):
        self.events = [] # (time, priority, counter, event_type, data)
        self.event_counter = 0
        self.now = 0.0
        self.nodes: Dict[str, GateNode] = {}
        self.rng = rng if rng else None # np.random.default_rng()
        self.sampling_interval = float(sampling_interval) if sampling_interval else 0.0
        self.next_sample_time = 0.0

        self.results = {
            "completed_jobs": [],
            "wip_history": []
        }

    def add_node(self, node: GateNode):
        self.nodes[node.node_id] = node

    def schedule_event(self, time: float, event_type: str, data: Any, priority: int = 10):
        heapq.heappush(self.events, (time, priority, self.event_counter, event_type, data))
        self.event_counter += 1

    def _snapshot_wip(self, at_time: float):
        node_wip = {}
        for node_id, node in self.nodes.items():
            in_queue = len(getattr(node, "queue", []))
            in_service = 0
            if hasattr(node, "busy_servers"):
                in_service = int(getattr(node, "busy_servers", 0))
            node_wip[node_id] = in_queue + in_service

        self.results["wip_history"].append({
            "time": float(at_time),
            "node_wip": node_wip,
            "total_wip": int(sum(node_wip.values()))
        })

    def run(self, max_days: float):
        # æœ€åˆã®ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ
        if self.sampling_interval > 0:
            self.next_sample_time = 0.0
            self._snapshot_wip(0.0)

        while self.events:
            time, priority, counter, event_type, data = heapq.heappop(self.events)
            if time > max_days:
                self.now = max_days
                break

            self.now = time
            self.handle_event(event_type, data)

            # WIPã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆä¸€å®šé–“éš”ã§ï¼‰
            if self.sampling_interval > 0:
                while self.next_sample_time + self.sampling_interval <= self.now + 1e-12:
                    self.next_sample_time += self.sampling_interval
                    if self.next_sample_time <= max_days + 1e-12:
                        self._snapshot_wip(self.next_sample_time)

    def handle_event(self, event_type: str, data: Any):
        if event_type == "ARRIVAL":
            job = data["job"]
            target_node_id = data["target_node"]
            if target_node_id in self.nodes:
                self.nodes[target_node_id].enqueue(job, self.now)
                self.check_node_activation(target_node_id)
            else:
                # çµ‚ç«¯ãƒãƒ¼ãƒ‰
                self.results["completed_jobs"].append(job)

        elif event_type == "PROCESS_READY":
            node_id = data["node_id"]
            if node_id in self.nodes:
                self.nodes[node_id].process(self.now)

        elif event_type == "WORK_COMPLETE":
            node_id = data["node_id"]
            job = data["job"]
            self.nodes[node_id].on_work_complete(job, self.now)

        elif event_type == "MEETING_START":
            node_id = data["node_id"]
            self.nodes[node_id].process(self.now)

    def check_node_activation(self, node_id: str):
        if self.nodes[node_id].can_process(self.now):
            # å³åº§ã«å‡¦ç†é–‹å§‹å¯èƒ½ãªå ´åˆã¯ã‚¤ãƒ™ãƒ³ãƒˆã‚’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«
            self.schedule_event(self.now, "PROCESS_READY", {"node_id": node_id}, priority=8)

    def get_total_wip(self) -> int:
        total = 0
        for node in self.nodes.values():
            total += len(node.queue)
        return total
```


---

### 2) ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã«ã€Œãƒãƒ¼ãƒ‰åˆ¥å¹³å‡WIPã€ç­‰ã‚’è¿½åŠ 
```python
import numpy as np
from typing import List, Dict, Any
from core.entities import Job

def calculate_metrics(completed_jobs: List[Job], nodes_stats: List[Dict[str, Any]], total_days: float, wip_history: List[Dict[str, Any]] = None):
    if not completed_jobs:
        return {"error": "No jobs completed"}

    lead_times = [job.history[-1]["time"] - job.created_at for job in completed_jobs]
    rework_counts = [job.rework_count for job in completed_jobs]

    # CCDFã®è¨ˆç®—ç”¨ãƒ‡ãƒ¼ã‚¿
    sorted_lt = np.sort(lead_times)
    ccdf_y = 1.0 - np.arange(1, len(sorted_lt) + 1) / len(sorted_lt)

    # WIPé›†è¨ˆï¼ˆãƒãƒ¼ãƒ‰åˆ¥å¹³å‡WIPï¼‰
    avg_wip_total = 0.0
    avg_wip_by_node: Dict[str, float] = {}
    if wip_history:
        totals = [x.get("total_wip", 0) for x in wip_history]
        avg_wip_total = float(np.mean(totals)) if totals else 0.0

        # node_wipã‚’ç¸¦æŒã¡ã«ã—ã¦å¹³å‡
        acc: Dict[str, List[int]] = {}
        for row in wip_history:
            node_wip = row.get("node_wip", {}) or {}
            for node_id, v in node_wip.items():
                acc.setdefault(node_id, []).append(int(v))
        avg_wip_by_node = {k: float(np.mean(vs)) for k, vs in acc.items()}

    metrics = {
        "summary": {
            "completed_count": len(completed_jobs),
            "throughput": len(completed_jobs) / total_days,
            "lead_time_p50": float(np.percentile(lead_times, 50)),
            "lead_time_p90": float(np.percentile(lead_times, 90)),
            "lead_time_p95": float(np.percentile(lead_times, 95)),
            "avg_reworks": float(np.mean(rework_counts)),
            "max_reworks": int(np.max(rework_counts)),
            "avg_wip": avg_wip_total
        },
        "gate_stats": nodes_stats,
        "wip": {
            "avg_total": avg_wip_total,
            "avg_by_node": avg_wip_by_node,
            "history": wip_history or []
        },
        "ccdf": {
            "x": sorted_lt.tolist(),
            "y": ccdf_y.tolist()
        },
        "raw_lead_times": lead_times,
        "raw_rework_counts": rework_counts
    }

    return metrics
```


---

### 3) æ¨™æº–ãƒ•ãƒ­ãƒ¼ï¼ˆSMALL_EXPâ†’PROTOâ†’BUNDLEâ†’DRï¼‰ã‚’ Ver7ãƒ¡ã‚¤ãƒ³ã§å›ã™é–¢æ•°ã‚’è¿½åŠ 
`runner/adapters.py` ã® `setup_standard_flow()` ã‚’å‘¼ã³ã€ãã“ã‹ã‚‰ metrics ã‚’ä½œã‚‹ã ã‘ã«ã—ã¾ã™ã€‚

```python
import os
import sys
import numpy as np
import concurrent.futures
import multiprocessing

# ãƒ‘ã‚¹è¨­å®š
current_dir = os.path.dirname(os.path.abspath(__file__))
if current_dir not in sys.path:
    sys.path.append(current_dir)

from analysis.metrics import calculate_metrics
from runner.adapters import setup_standard_flow

def simulate_standard_flow_v7(
    days=365,
    arrival_rate=0.5,
    small_exp_duration=5,
    proto_duration=20,
    bundle_size=3,
    dr_period=90,
    dr_capacity=10,   # ç¾çŠ¶ã¯approversã®capacityå´ã«å¯„ã›ã‚‹ãªã‚‰ä»Šå¾Œåæ˜ ï¼ˆã“ã“ã§ã¯æ¸©å­˜ï¼‰
    dr_quality=0.8,   # åŒä¸Šï¼ˆMeetingGateã®qualityã¸å¯„ã›ã‚‹ãªã‚‰ä»Šå¾Œåæ˜ ï¼‰
    rework_load_factor=1.0,
    max_rework_cycles=5,
    decay=0.7,
    approvers=2,
    seed=None,
    sampling_interval=1.0
):
    """
    Ver7 æ¨™æº–ãƒ•ãƒ­ãƒ¼ç‰ˆï¼ˆSMALL_EXPâ†’PROTOâ†’BUNDLEâ†’DR_GATEï¼‰
    runner/adapters.py ã® setup_standard_flow ã‚’ãƒ¡ã‚¤ãƒ³æ¡ç”¨ã™ã‚‹ã€‚
    """
    rng = np.random.default_rng(seed)

    engine = setup_standard_flow(
        rng,
        days=days,
        arrival_rate=arrival_rate,
        small_exp_duration=small_exp_duration,
        proto_duration=proto_duration,
        bundle_size=bundle_size,
        dr_period=dr_period,
        dr_capacity=dr_capacity,
        dr_quality=dr_quality,
        rework_load_factor=rework_load_factor,
        max_rework_cycles=max_rework_cycles,
        decay=decay,
        approvers=approvers
    )

    # sampling_interval ã‚’ engine ã«åæ˜ ï¼ˆsetupå´ãŒ engine ã‚’ç”Ÿæˆã—ã¦ã„ã‚‹ãŸã‚å¾Œä»˜ã‘ï¼‰
    engine.sampling_interval = float(sampling_interval) if sampling_interval else 0.0
    engine.next_sample_time = 0.0

    engine.run(days)

    nodes_stats = [node.stats() for node in engine.nodes.values()]
    m = calculate_metrics(
        engine.results["completed_jobs"],
        nodes_stats,
        days,
        wip_history=engine.results.get("wip_history", [])
    )

    if "error" in m:
        summary = {
            "approved_count": 0,
            "throughput": 0,
            "avg_wait": 0,
            "p90_wait": 0,
            "p95_wait": 0,
            "avg_wip": 0,
            "avg_reworks": 0,
            "max_reworks": 0,
        }
    else:
        summary = {
            "approved_count": m["summary"]["completed_count"],
            "throughput": m["summary"]["throughput"],
            "avg_wait": m["summary"]["lead_time_p50"],
            "p90_wait": m["summary"]["lead_time_p90"],
            "p95_wait": m["summary"]["lead_time_p95"],
            "avg_wip": m["summary"].get("avg_wip", 0),
            "avg_reworks": m["summary"]["avg_reworks"],
            "max_reworks": m["summary"]["max_reworks"],
        }

    return {
        "summary": summary,
        "metrics": m,
        "logs": {
            "lead_times": m.get("raw_lead_times", []),
            "rework_counts": m.get("raw_rework_counts", []),
            "wip_history": m.get("wip", {}).get("history", []),
        }
    }

def _single_trial(args):
    params, seed = args
    return simulate_standard_flow_v7(**params, seed=seed)

def run_monte_carlo_v7(n_trials=100, use_parallel=True, **params):
    """
    ãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­ï¼ˆæ¨™æº–ãƒ•ãƒ­ãƒ¼ç‰ˆï¼‰
    seedã¯ trial_id ã‚’ãã®ã¾ã¾ä½¿ã†ï¼ˆbase_seed ã‚’è¶³ã—ãŸã„å ´åˆã¯ run_v7.py å´ã§æ¸¡ã™ï¼‰
    """
    args = [(params, i) for i in range(n_trials)]

    if use_parallel and n_trials > 1:
        cpu_count = multiprocessing.cpu_count()
        with concurrent.futures.ProcessPoolExecutor(max_workers=cpu_count) as executor:
            results = list(executor.map(_single_trial, args))
    else:
        results = [_single_trial(arg) for arg in args]

    return results

def latin_hypercube_sampling(n_samples, param_ranges):
    # ... existing code ...
    n_params = len(param_ranges)
    lower_limits = np.arange(0, n_samples) / n_samples
    upper_limits = np.arange(1, n_samples + 1) / n_samples

    u_samples = np.zeros((n_samples, n_params))
    for i in range(n_params):
        samples = np.random.uniform(low=lower_limits, high=upper_limits, size=n_samples)
        np.random.shuffle(samples)
        u_samples[:, i] = samples

    scaled_samples = []
    param_names = list(param_ranges.keys())
    for j in range(n_samples):
        sample_dict = {}
        for i, name in enumerate(param_names):
            p_min, p_max = param_ranges[name]
            sample_dict[name] = p_min + u_samples[j, i] * (p_max - p_min)
        scaled_samples.append(sample_dict)

    return scaled_samples
```


> ãƒã‚¤ãƒ³ãƒˆï¼šæ—¢å­˜ã® `run_v7.py` ã¯ `run_monte_carlo_v7()` ã‚’å‘¼ã‚“ã§ã„ã‚‹ã®ã§ã€ã“ã“ã‚’ã€Œæ¨™æº–ãƒ•ãƒ­ãƒ¼ç‰ˆã€ã«ç½®ãæ›ãˆã‚‹ã®ãŒä¸€ç•ªå½±éŸ¿ãŒå°ã•ã„ã§ã™ï¼ˆrun_v7.py å´ã®æ”¹ä¿®ãŒè»½ã„ï¼‰ã€‚

---

### 4) å¯è¦–åŒ–ã‚’â€œã‚²ãƒ¼ãƒˆåˆ¥â€ã¸ï¼ˆè©°ã¾ã‚ŠãŒä¸€ç™ºã§è¦‹ãˆã‚‹ï¼‰
ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—2æšã‚’è¿½åŠ ã—ã¾ã™ï¼š
- **ã‚·ãƒŠãƒªã‚ª Ã— ã‚²ãƒ¼ãƒˆ** ã® `avg_wait_time`ï¼ˆã‚²ãƒ¼ãƒˆåˆ¥å¾…ã¡ï¼‰
- **ã‚·ãƒŠãƒªã‚ª Ã— ã‚²ãƒ¼ãƒˆ** ã® `avg_wip`ï¼ˆã‚²ãƒ¼ãƒˆåˆ¥WIPï¼šæ™‚é–“å¹³å‡ï¼‰

```python
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import pandas as pd

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
plt.rcParams['font.family'] = 'sans-serif'
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'Hiragino Sans', 'IPAexGothic', 'sans-serif']

def plot_comparison_with_ci(comparison_results, title="ã‚·ãƒŠãƒªã‚ªæ¯”è¼ƒ (95%ä¿¡é ¼åŒºé–“)"):
    # ... existing code ...
    labels = list(comparison_results.keys())
    means = [comparison_results[l]["mean"] for l in labels]
    lows = [comparison_results[l]["ci"][0] for l in labels]
    highs = [comparison_results[l]["ci"][1] for l in labels]

    yerr = [np.array(means) - np.array(lows), np.array(highs) - np.array(means)]

    plt.figure(figsize=(10, 6))
    bars = plt.bar(labels, means, yerr=yerr, capsize=5, color='skyblue', alpha=0.8)

    plt.title(title)
    plt.ylabel("ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ (VP/day)")
    plt.grid(axis='y', linestyle='--', alpha=0.7)

    for bar in bars:
        yval = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2, yval, f"{yval:.2f}",
                 ha='center', va='bottom', fontweight='bold')

    plt.tight_layout()

def plot_gate_wait_heatmap(gate_stats_by_scenario: dict, title="ã‚²ãƒ¼ãƒˆåˆ¥ å¹³å‡å¾…ã¡æ™‚é–“ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—"):
    """
    gate_stats_by_scenario:
      { scenario_name: [ {"node_id": "...", "avg_wait_time": ...}, ... ], ... }
    """
    rows = []
    for scenario, stats in gate_stats_by_scenario.items():
        for s in stats:
            rows.append({
                "Scenario": scenario,
                "Gate": s.get("node_id"),
                "AvgWait": s.get("avg_wait_time", 0.0)
            })
    df = pd.DataFrame(rows)
    if df.empty:
        return

    pivot = df.pivot_table(index="Scenario", columns="Gate", values="AvgWait", aggfunc="mean").fillna(0.0)

    plt.figure(figsize=(max(8, 1.2 * pivot.shape[1]), max(4, 0.7 * pivot.shape[0])))
    sns.heatmap(pivot, annot=True, fmt=".1f", cmap="YlOrRd")
    plt.title(title)
    plt.xlabel("Gate")
    plt.ylabel("Scenario")
    plt.tight_layout()

def plot_gate_wip_heatmap(avg_wip_by_node_by_scenario: dict, title="ã‚²ãƒ¼ãƒˆåˆ¥ å¹³å‡WIPãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—"):
    """
    avg_wip_by_node_by_scenario:
      { scenario_name: { node_id: avg_wip, ... }, ... }
    """
    rows = []
    for scenario, d in avg_wip_by_node_by_scenario.items():
        for node_id, v in (d or {}).items():
            rows.append({
                "Scenario": scenario,
                "Gate": node_id,
                "AvgWIP": float(v)
            })
    df = pd.DataFrame(rows)
    if df.empty:
        return

    pivot = df.pivot_table(index="Scenario", columns="Gate", values="AvgWIP", aggfunc="mean").fillna(0.0)

    plt.figure(figsize=(max(8, 1.2 * pivot.shape[1]), max(4, 0.7 * pivot.shape[0])))
    sns.heatmap(pivot, annot=True, fmt=".1f", cmap="PuBu")
    plt.title(title)
    plt.xlabel("Gate")
    plt.ylabel("Scenario")
    plt.tight_layout()

def plot_doe_analysis(doe_df, target_col="throughput", title="DOE (å®Ÿé¨“è¨ˆç”»æ³•) æ„Ÿåº¦åˆ†æ"):
    # ... existing code ...
    param_cols = [c for c in doe_df.columns if c != target_col]
    n_params = len(param_cols)

    fig, axes = plt.subplots(1, n_params, figsize=(4 * n_params, 5), sharey=True)
    if n_params == 1: axes = [axes]

    for i, col in enumerate(param_cols):
        sns.regplot(x=col, y=target_col, data=doe_df, ax=axes[i], scatter_kws={'alpha':0.5})
        axes[i].set_title(f"{col} vs {target_col}")
        axes[i].grid(True, alpha=0.3)

    plt.suptitle(title, fontsize=16)
    plt.tight_layout(rect=[0, 0.03, 1, 0.95])

def plot_quality_gate_status(gate_results, title="æ¤œè¨¼ã‚²ãƒ¼ãƒˆ (Quality Gates) ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹"):
    # ... existing code ...
    fig, ax = plt.subplots(figsize=(10, 4))
    ax.axis('off')

    rows = gate_results["gates"]
    data = [[r["name"], f"{r['value']:.4f}", r["threshold"], r["status"]] for r in rows]

    colors = []
    for r in rows:
        colors.append(['white', 'white', 'white', 'lightgreen' if r["status"] == "PASS" else 'tomato'])

    table = ax.table(cellText=data,
                    colLabels=["ã‚²ãƒ¼ãƒˆå", "ç¾åœ¨å€¤", "é–¾å€¤", "åˆ¤å®š"],
                    cellColours=colors,
                    loc='center',
                    cellLoc='center')

    table.auto_set_font_size(False)
    table.set_fontsize(10)
    table.scale(1.2, 1.8)

    overall_color = 'green' if gate_results["overall_status"] == "PASS" else 'red'
    plt.title(f"{title}\nç·åˆåˆ¤å®š: {gate_results['overall_status']}",
              color=overall_color, fontsize=14, fontweight='bold')
    plt.tight_layout()

# ... existing code ...
```


---

### 5) run_v7.pyï¼šStep2ã®åé›†ã«ã€Œã‚²ãƒ¼ãƒˆåˆ¥ stats / WIPå¹³å‡ã€ã‚’è¿½åŠ ã—ã¦å›³ã‚’å‡ºã™
```python
import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import sys

# å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’åŸºæº–ã«ã™ã‚‹ï¼ˆçµ¶å¯¾ãƒ‘ã‚¹è§£æ±ºï¼‰
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
if CURRENT_DIR not in sys.path:
    sys.path.append(CURRENT_DIR)

from simulator_v7 import run_monte_carlo_v7, latin_hypercube_sampling
from analyzer_v7 import AnalyzerV7
import visualizer_v7 as viz

# å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
OUT_DIR = os.path.join(CURRENT_DIR, "output")
os.makedirs(OUT_DIR, exist_ok=True)

def run_v7_pipeline():
    print("=== DX4MGR Ver7: ãƒ‘ã‚¹ä¸æ•´åˆè§£æ¶ˆãƒ»ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåˆ·æ–°ãƒ¢ãƒ‡ãƒ« ===")

    # 1. ã‚·ãƒŠãƒªã‚ªèª­ã¿è¾¼ã¿
    csv_path = os.path.join(CURRENT_DIR, "scenarios.csv")
    if not os.path.exists(csv_path):
        print(f"Error: {csv_path} not found.")
        return

    df_scenarios = pd.read_csv(csv_path)
    analyzer = AnalyzerV7(OUT_DIR)

    # 2. DOE (å®Ÿé¨“è¨ˆç”»æ³•) ã«ã‚ˆã‚‹æ¢ç´¢ï¼ˆâ€»ã“ã“ã¯å¾Œã§æ¨™æº–ãƒ•ãƒ­ãƒ¼ç‰ˆDOEã¸æ‹¡å¼µå¯ï¼‰
    print("\n[Step 1: DOE (å®Ÿé¨“è¨ˆç”»æ³•) ã«ã‚ˆã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¢ç´¢]")
    doe_ranges = {
        "rework_load_factor": (0.2, 1.5),
        "dr_period": (30, 180),
        "proto_duration": (10, 40),
    }
    fixed_params = {
        "days": 180,
        "arrival_rate": 0.5,
        "small_exp_duration": 5,
        "bundle_size": 3,
        "approvers": 2,
        "max_rework_cycles": 5,
        "decay": 0.7,
        "sampling_interval": 5.0
    }

    doe_samples = latin_hypercube_sampling(n_samples=30, param_ranges=doe_ranges)

    print(f"  {len(doe_samples)} ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿çµ„ã¿åˆã‚ã›ã‚’æ¤œè¨¼ä¸­...")
    doe_results = []
    for sample in doe_samples:
        params = {**fixed_params, **sample}
        # DOEã¯è»½ã1ãƒˆãƒ©ã‚¤ã‚¢ãƒ«è©•ä¾¡ï¼ˆå¿…è¦ãªã‚‰n_trialsåŒ–ï¼‰
        res = run_monte_carlo_v7(n_trials=1, use_parallel=False, **params)[0]
        doe_results.append({**sample, "throughput": res["summary"]["throughput"]})

    doe_df = pd.DataFrame(doe_results)
    viz.plot_doe_analysis(doe_df, title="Ver7 DOE æ„Ÿåº¦åˆ†æï¼ˆæ¨™æº–ãƒ•ãƒ­ãƒ¼ï¼‰")
    plt.savefig(os.path.join(OUT_DIR, "v7_step1_doe_analysis.png"))
    plt.close()

    # 3. ãƒ¡ã‚¤ãƒ³ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ (ä¸¦åˆ—å®Ÿè¡Œ)
    print("\n[Step 2: å„ã‚·ãƒŠãƒªã‚ªã®ä¸¦åˆ—ãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³]")
    all_summaries = {}
    all_waits = {}
    all_reworks = {}
    gate_reports = {}

    gate_stats_by_scenario = {}
    avg_wip_by_node_by_scenario = {}

    criteria = {
        "min_throughput": 2.0,
        "max_wait": 30.0,
        "max_cv": 0.5,
        "max_ci_width": 0.2,
        "max_reworks": 1.5
    }

    for _, row in df_scenarios.iterrows():
        name = row['scenario_name']
        print(f"  ã‚·ãƒŠãƒªã‚ªå®Ÿè¡Œä¸­: {name} ...")

        params = row.to_dict()
        n_trials = int(params.pop('n_trials'))
        params.pop('scenario_name')

        # å‹å¤‰æ›ï¼ˆå¿…è¦ã«å¿œã˜ã¦è¿½åŠ ï¼‰
        for k in ['days', 'approvers', 'bundle_size']:
            if k in params and pd.notna(params[k]):
                params[k] = int(params[k])

        trials = run_monte_carlo_v7(n_trials=n_trials, use_parallel=True, **params)

        summaries = [t["summary"] for t in trials]
        all_summaries[name] = summaries

        all_waits[name] = [lt for t in trials for lt in t["logs"]["lead_times"]]
        all_reworks[name] = [rc for t in trials for rc in t["logs"]["rework_counts"]]

        # ã‚²ãƒ¼ãƒˆåˆ¥statsï¼ˆå„trialã® metrics.gate_stats ã‚’å¹³å‡åŒ–ï¼‰
        # gate_stats ã¯ node_id ã§æƒãˆã¦å¹³å‡å¾…ã¡ã‚’å–ã‚ŠãŸã„ã®ã§ã€ç°¡æ˜“ã« â€œtrialå¹³å‡â†’ã‚·ãƒŠãƒªã‚ªå¹³å‡â€
        gate_rows = []
        for t in trials:
            m = t.get("metrics", {})
            for s in (m.get("gate_stats", []) or []):
                gate_rows.append({"node_id": s.get("node_id"), "avg_wait_time": s.get("avg_wait_time", 0.0)})

        if gate_rows:
            df_gate = pd.DataFrame(gate_rows).groupby("node_id", as_index=False)["avg_wait_time"].mean()
            gate_stats_by_scenario[name] = df_gate.to_dict("records")
        else:
            gate_stats_by_scenario[name] = []

        # WIPï¼ˆãƒãƒ¼ãƒ‰åˆ¥å¹³å‡WIPï¼‰ã‚’ trial å…¨ä½“ã‹ã‚‰å¹³å‡
        wip_rows = []
        for t in trials:
            m = t.get("metrics", {})
            w = (m.get("wip", {}) or {}).get("avg_by_node", {}) or {}
            for node_id, v in w.items():
                wip_rows.append({"node_id": node_id, "avg_wip": float(v)})

        if wip_rows:
            df_wip = pd.DataFrame(wip_rows).groupby("node_id", as_index=False)["avg_wip"].mean()
            avg_wip_by_node_by_scenario[name] = dict(zip(df_wip["node_id"], df_wip["avg_wip"]))
        else:
            avg_wip_by_node_by_scenario[name] = {}

        gate_res = analyzer.run_quality_gates(summaries, criteria)
        gate_reports[name] = gate_res

        viz.plot_quality_gate_status(gate_res, title=f"Quality Gate: {name}")
        plt.savefig(os.path.join(OUT_DIR, f"v7_step2_gate_{name}.png"))
        plt.close()

    # 4. çµ±è¨ˆè§£æã¨æ¯”è¼ƒ
    print("\n[Step 3: çµ±è¨ˆçš„è§£æã¨æ¯”è¼ƒ]")
    baseline_name = df_scenarios.iloc[0]['scenario_name']
    comparison_summary = {}

    print(f"  åŸºæº–(Baseline): {baseline_name}")
    for name in all_summaries.keys():
        m, low, high = analyzer.calculate_confidence_interval([s["throughput"] for s in all_summaries[name]])
        comparison_summary[name] = {"mean": m, "ci": [low, high]}

        if name != baseline_name:
            comp = analyzer.compare_scenarios(all_summaries[baseline_name], all_summaries[name])
            sig_str = "ã€æœ‰æ„å·®ã‚ã‚Šã€‘" if comp['statistically_significant'] else "ã€æœ‰æ„å·®ãªã—ã€‘"
            print(f"  - {name:20}: æ”¹å–„ç‡ {comp['improvement_pct']:+6.1f}% {sig_str}")

    # 5. å¯è¦–åŒ–
    print("\n[Step 4: å¯è¦–åŒ–ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ]")
    viz.plot_comparison_with_ci(comparison_summary, title="å…¨ã‚·ãƒŠãƒªã‚ªæ¯”è¼ƒ: ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ(Ver7æ¨™æº–ãƒ•ãƒ­ãƒ¼)")
    plt.savefig(os.path.join(OUT_DIR, "v7_step3_comparison_ci.png"))
    plt.close()

    viz.plot_wait_time_distribution(all_waits, title="Ver7 å¾…ã¡æ™‚é–“(Lead Time)åˆ†å¸ƒæ¯”è¼ƒ")
    plt.savefig(os.path.join(OUT_DIR, "v7_step3_compare_violin.png"))
    plt.close()

    viz.plot_rework_distribution(all_reworks, title="Ver7 å·®ã—æˆ»ã—å›æ•°åˆ†å¸ƒæ¯”è¼ƒ")
    plt.savefig(os.path.join(OUT_DIR, "v7_step3_compare_reworks.png"))
    plt.close()

    viz.plot_gate_wait_heatmap(gate_stats_by_scenario, title="Ver7 ã‚²ãƒ¼ãƒˆåˆ¥ å¹³å‡å¾…ã¡æ™‚é–“ï¼ˆè©°ã¾ã‚Šï¼‰")
    plt.savefig(os.path.join(OUT_DIR, "v7_step4_gate_wait_heatmap.png"))
    plt.close()

    viz.plot_gate_wip_heatmap(avg_wip_by_node_by_scenario, title="Ver7 ã‚²ãƒ¼ãƒˆåˆ¥ å¹³å‡WIPï¼ˆæ»ç•™ï¼‰")
    plt.savefig(os.path.join(OUT_DIR, "v7_step4_gate_wip_heatmap.png"))
    plt.close()

    # 6. ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
    analyzer.save_analysis_report({
        "criteria": criteria,
        "gate_reports": gate_reports,
        "comparison_summary": comparison_summary
    }, "v7_final_analysis_report.json")

    print(f"\n=== å…¨å·¥ç¨‹å®Œäº† ===")
    print(f"ç”»åƒãŠã‚ˆã³åˆ†æãƒ¬ãƒãƒ¼ãƒˆã¯ä»¥ä¸‹ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ:\n{os.path.abspath(OUT_DIR)}")

if __name__ == "__main__":
    run_v7_pipeline()
```


---

## ã“ã‚Œã§å¾—ã‚‰ã‚Œã‚‹ã€Œå¼·åŠ›ãªå¯è¦–åŒ–ã€
- **ã‚²ãƒ¼ãƒˆåˆ¥ã®å¹³å‡å¾…ã¡æ™‚é–“**ï¼šã©ã“ãŒè©°ã¾ã‚Šã‹ä¸€ç›®ã§åˆ†ã‹ã‚‹ï¼ˆSMALL_EXP / PROTO / BUNDLE / DR_GATEï¼‰
- **ã‚²ãƒ¼ãƒˆåˆ¥ã®å¹³å‡WIP**ï¼šè©°ã¾ã‚ŠãŒã€Œå¾…ã¡ã€ãªã®ã‹ã€Œæ»ç•™é‡ã€ãªã®ã‹ãŒè¦‹ãˆã‚‹
  â†’ ãŸã¨ãˆã°ã€ŒBUNDLE ã§WIPãŒå¢—ãˆã‚‹ï¼æŸã­å¾…ã¡ãŒãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã€ãªã©ãŒç›´æ„Ÿçš„ã«å‡ºã¾ã™

---

## æ¬¡ã®ä¸€æ‰‹ï¼ˆå“è³ªã‚’ã‚‚ã†ä¸€æ®µä¸Šã’ã‚‹ãªã‚‰ï¼‰
ä»Šã®æ¨™æº–ãƒ•ãƒ­ãƒ¼å´ã¯ã€å·®ã—æˆ»ã—ã§ `Task` ã¯å¢—ãˆã¾ã™ãŒã€ãã® `Task` ãŒ **WorkGateã®å‡¦ç†æ™‚é–“ã«â€œç¢ºå®Ÿã«ä¹—ã‚‹â€**ã¨ã“ã‚ã¯ã¾ã å¼±ã„ã§ã™ã€‚
ã€Œå¢—æ®–ï¼é…å»¶ã®å°¾ï¼ˆP90/P95ï¼‰ãŒå¤ªã‚‹ã€ã‚’å¼·ãã—ãŸã„ãªã‚‰ã€æ¬¡ã¯

- å·®ã—æˆ»ã—ã§å¢—ãˆãŸ Task æ•°ã«å¿œã˜ã¦ã€SMALL_EXPï¼ˆã¾ãŸã¯PROTOï¼‰ã§è¿½åŠ ä½œæ¥­æ™‚é–“ã‚’ä¸Šä¹—ã›

ã‚’å…¥ã‚Œã‚‹ã®ãŒåŠ¹ãã¾ã™ï¼ˆã“ã®èª¿æ•´ã¯ãƒ¢ãƒ‡ãƒ«ã®è¡¨ç¾åŠ›ãŒä¸€æ°—ã«ä¸ŠãŒã‚Šã¾ã™ï¼‰ã€‚


ğŸŸ©ãƒ†ã‚¹ãƒˆãƒ»è¿½åŠ æ¤œè¨¼çµæœğŸŸ©

Ver8ã‚’ãƒ™ãƒ¼ã‚¹ã«ã€50ã‚µãƒ³ãƒ—ãƒ«ã®DOEï¼ˆå®Ÿé¨“è¨ˆç”»æ³•ï¼‰ã¨5ã¤ã®ãƒ‰ãƒ©ã‚¹ãƒ†ã‚£ãƒƒã‚¯ãªæ¯”è¼ƒã‚·ãƒŠãƒªã‚ªã‚’ç”¨ã„ãŸå¤§è¦æ¨¡æ¤œè¨¼ã‚’å®Ÿæ–½ã—ã¾ã—ãŸã€‚
å®Ÿæ–½å†…å®¹
â€¢
ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ‹¡å¼µ: 6ç¨®é¡ã®ä¸»è¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆæŠ•å…¥é »åº¦ã€æ‰‹æˆ»ã‚Šè² è·ã€ãƒ¬ãƒ“ãƒ¥ãƒ¼å‘¨æœŸã€ãƒãƒƒãƒã‚µã‚¤ã‚ºã€ãƒªã‚½ãƒ¼ã‚¹æ•°ã€è©¦ä½œæœŸé–“ï¼‰ã‚’å¤‰å‹•ã•ã›ã€çµ„ç¹”ã®é™ç•Œæ€§èƒ½ã‚’èª¿æŸ»ã—ã¾ã—ãŸã€‚
â€¢
æ¤œè¨¼ã‚·ãƒŠãƒªã‚ªã®åˆ·æ–°: ã€Œçµ„ç¹”å´©å£Šãƒªã‚¹ã‚¯ã€ã€Œæ¥µç«¯ãªã‚¢ã‚¸ãƒ£ã‚¤ãƒ«ã€ã€Œç¡¬ç›´ã—ãŸã‚¦ã‚©ãƒ¼ã‚¿ãƒ¼ãƒ•ã‚©ãƒ¼ãƒ«ã€ã€Œç†æƒ³çš„ãªãƒªãƒ¼ãƒ³ã€ã¨ã„ã†ã€Baselineã‹ã‚‰å¤§ããä¹–é›¢ã—ãŸ5ã¤ã®ã‚·ãƒŠãƒªã‚ªã§æ¯”è¼ƒã‚’è¡Œã„ã¾ã—ãŸã€‚
â€¢
è§£æã®å®Ÿè¡Œ: æ–°ãŸã«ä½œæˆã—ãŸ run_v8_extensive.py ã«ã‚ˆã‚Šã€ä¸¦åˆ—ãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã—ã€çµ±è¨ˆçš„æœ‰æ„å·®ã¨ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã‚’ç‰¹å®šã—ã¾ã—ãŸã€‚
ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®åå‰ã¨å‹•æ©Ÿ
| ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å | å‹•æ©Ÿ | | :--- | :--- | | arrival_rate | æ¡ˆä»¶æŠ•å…¥ãŒçµ„ç¹”å®¹é‡ã‚’è¶…ãˆãŸéš›ã®ã€Œè©°ã¾ã‚Šï¼ˆç›¸è»¢ç§»ï¼‰ã€ã®é™ç•Œç‚¹ã‚’ç‰¹å®šã™ã‚‹ãŸã‚ã€‚ | | rework_load_factor | æ‰‹æˆ»ã‚ŠãŒè»½å¾®ãªä¿®æ­£ã‹ã€å…¨ä½“æ³¢åŠã‚’ä¼´ã†æ³¥æ²¼çŠ¶æ…‹ï¼ˆ2.0å€ï¼‰ã‹ã«ã‚ˆã‚‹æ„Ÿåº¦ã‚’æ¸¬ã‚‹ãŸã‚ã€‚ | | dr_period | ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯é »åº¦ã®çŸ­ç¸®ãŒã€ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ çŸ­ç¸®ã«ã©ã‚Œã»ã©å¯„ä¸ã™ã‚‹ã‹ã‚’æŠŠæ¡ã™ã‚‹ãŸã‚ã€‚ | | bundle_size | æ‰¿èªã®å¡Šï¼ˆãƒãƒƒãƒã‚µã‚¤ã‚ºï¼‰ãŒã€ãƒªãƒˆãƒ«ã®æ³•å‰‡ã«åŸºã¥ãã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’ã©ã†å¤‰åŒ–ã•ã›ã‚‹ã‹æ¤œè¨¼ã™ã‚‹ãŸã‚ã€‚ | | approvers | ãƒªã‚½ãƒ¼ã‚¹æŠ•å…¥ãŒã€è¤‡é›‘ãªä¾å­˜ãƒ•ãƒ­ãƒ¼ã«ãŠã„ã¦ç·šå½¢ã«åŠ¹æœã‚’ç™ºæ®ã™ã‚‹ã‹ç¢ºèªã™ã‚‹ãŸã‚ã€‚ | | proto_duration | å‰å·¥ç¨‹ã§ã®ã€Œä»•è¾¼ã¿ã€ãŒã€å¾Œæ®µã®æ‰‹æˆ»ã‚Šå‰Šæ¸›ã«ã‚ˆã‚‹åˆ©ç›Šã‚’ä¸Šå›ã‚‹ã‹ãƒãƒ©ãƒ³ã‚¹ã‚’è¦‹ã‚‹ãŸã‚ã€‚ |
çµæœã«å¯¾ã™ã‚‹è€ƒå¯Ÿ
â€¢
ã‚¢ã‚¸ãƒ£ã‚¤ãƒ«åŒ–ã®åŠ‡çš„ãªåŠ¹æœ: Agile_Extremeï¼ˆå°ãƒãƒƒãƒãƒ»é«˜é »åº¦DRï¼‰ã¯ã€Baselineã«å¯¾ã—ã¦ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆãŒ +530.3% ã¨ã„ã†åœ§å€’çš„ãªå‘ä¸Šã‚’ç¤ºã—ã¾ã—ãŸã€‚ã“ã‚Œã¯ã€WIPã®æ»ç•™ã‚’æœ€å°åŒ–ã™ã‚‹ã“ã¨ãŒçµ„ç¹”ã®ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆæœ€å¤§åŒ–ã«ç›´çµã™ã‚‹ã“ã¨ã‚’è¨¼æ˜ã—ã¦ã„ã¾ã™ã€‚
â€¢
å·¨å¤§ãƒãƒƒãƒã®ãƒªã‚¹ã‚¯: Waterfall_Rigidï¼ˆå¤§ãƒãƒƒãƒãƒ»ä½é »åº¦DRï¼‰ã¯ã€ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆãŒ Baseline ã® -86.5% ã¾ã§ä½ä¸‹ã—ã€å“è³ªã‚²ãƒ¼ãƒˆã‚’ã€ŒFAILã€ã—ã¾ã—ãŸã€‚ä¸€åº¦ã®æ»ç•™ãŒå…¨ã¦ã®æ¡ˆä»¶ã‚’å·»ãè¾¼ã‚€ãŸã‚ã€å·¨å¤§ãªä»•äº‹å˜ä½ã¯æ¥µã‚ã¦éåŠ¹ç‡ã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚
â€¢
éš ã‚ŒãŸå´©å£Šãƒªã‚¹ã‚¯: Collapse_Risk ã‚·ãƒŠãƒªã‚ªã§ã¯ã€ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã¯ç¶­æŒã§ãã¦ã„ã‚‹ã‚‚ã®ã®ã€å¹³å‡å¾…ã¡æ™‚é–“ãŒ Baseline ã® 1.5 å€ä»¥ä¸Šã«å¢—åŠ ã—ã¾ã—ãŸã€‚ã“ã‚Œã¯ç¾å ´ãŒé™ç•ŒçŠ¶æ…‹ã§ç¨¼åƒã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ãŠã‚Šã€ã‚ãšã‹ãªå¤‰å‹•ã§ç ´ç¶»ã™ã‚‹ãƒªã‚¹ã‚¯ã‚’å­•ã‚“ã§ã„ã‚‹ã“ã¨ãŒå¯è¦–åŒ–ã•ã‚Œã¾ã—ãŸã€‚
å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«
â€¢
v8_extensive_step1_doe.png: 50ã‚µãƒ³ãƒ—ãƒ«ã«ã‚ˆã‚‹æ„Ÿåº¦åˆ†æçµæœ
â€¢
v8_extensive_step3_ci.png: ãƒ‰ãƒ©ã‚¹ãƒ†ã‚£ãƒƒã‚¯ãƒ»ã‚·ãƒŠãƒªã‚ªé–“ã®ä¿¡é ¼åŒºé–“æ¯”è¼ƒ
â€¢
v8_extensive_step4_wait_heatmap.png: å„ã‚·ãƒŠãƒªã‚ªã«ãŠã‘ã‚‹ãƒãƒ¼ãƒ‰åˆ¥è©°ã¾ã‚Šç®‡æ‰€ã®å¯è¦–åŒ–
â€¢
v8_extensive_report.json: è©³ç´°ãªæ•°å€¤ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€ãƒ¬ãƒãƒ¼ãƒˆ